{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, SimpleRNN, Flatten\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels being merged to new category:  [2, 5]\n",
      "Merged into new category:  2\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.drop(columns=['label-fine'])\n",
    "test_df = test_df.drop(columns=['label-fine'])\n",
    "\n",
    "# Creating developmental set of 500 rows from train set\n",
    "train_df, dev_df = train_test_split(train_df, test_size=(500/len(train_df)), random_state=42)\n",
    "\n",
    "counts = train_df['label-coarse'].value_counts()\n",
    "\n",
    "# Find the labels with the lowest frequencies\n",
    "lowest_frequency = [counts.index[-1], counts.index[-2]]\n",
    "print(\"Labels being merged to new category: \", lowest_frequency)\n",
    "print(\"Merged into new category: \", lowest_frequency[0])\n",
    "\n",
    "# Replace these labels with new label: 6\n",
    "train_df.loc[(train_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = lowest_frequency[0]\n",
    "dev_df.loc[(dev_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = lowest_frequency[0]\n",
    "test_df.loc[(test_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = lowest_frequency[0]\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "dev_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>What is Mikhail Gorbachev 's middle initial ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the tail affect the flight of a kite ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What were the first three cities to have a pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the movie Jonathan Livingstone Seagull ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>What is a fear of home surroundings ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>4</td>\n",
       "      <td>How much Coca Cola is drunk in one day in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>2</td>\n",
       "      <td>What cathedral was Thomas Becket murdered in ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>3</td>\n",
       "      <td>What character in The Beverly Hillbillies has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>2</td>\n",
       "      <td>What does the River Seine empty into ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>3</td>\n",
       "      <td>What U.S. Congressman said : `` Keep the faith...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4952 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label-coarse                                               text\n",
       "0                2      What is Mikhail Gorbachev 's middle initial ?\n",
       "1                0    How does the tail affect the flight of a kite ?\n",
       "2                2  What were the first three cities to have a pop...\n",
       "3                1   What is the movie Jonathan Livingstone Seagull ?\n",
       "4                1              What is a fear of home surroundings ?\n",
       "...            ...                                                ...\n",
       "4947             4  How much Coca Cola is drunk in one day in the ...\n",
       "4948             2     What cathedral was Thomas Becket murdered in ?\n",
       "4949             3  What character in The Beverly Hillbillies has ...\n",
       "4950             2             What does the River Seine empty into ?\n",
       "4951             3  What U.S. Congressman said : `` Keep the faith...\n",
       "\n",
       "[4952 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about ~30 mins for first run, ~30 seconds afterwards\n",
    "word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is Mikhail Gorbachev 's middle initial ?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text using word_tokenize\n",
    "train_df['text'] = train_df['text'].apply(word_tokenize)\n",
    "dev_df['text'] = dev_df['text'].apply(word_tokenize)\n",
    "test_df['text'] = test_df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'is', 'Mikhail', 'Gorbachev', \"'s\", 'middle', 'initial', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total number of unique tokens in the training data \n",
    "unique_tokens = set()\n",
    "train_df['text'].apply(unique_tokens.update)\n",
    "# Remove words from the set which are not in the word2vec model\n",
    "unique_tokens = unique_tokens.intersection(set(word2vec.key_to_index.keys()))\n",
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(train_df['text'])\n",
    "train_df['text'] = tok.texts_to_sequences(train_df['text'])\n",
    "dev_df['text'] = tok.texts_to_sequences(dev_df['text'])\n",
    "test_df['text'] = tok.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1435, 1091, 10, 461, 3214, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = train_df['text']\n",
    "X_dev_sequences = dev_df['text']\n",
    "X_test_sequences = test_df['text']\n",
    "\n",
    "max_len = max([len(sentence) for sentence in train_df['text']])\n",
    "\n",
    "# Pad sequences to a fixed length (if needed)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen= max_len, padding='post', truncating='post')\n",
    "X_dev_padded = pad_sequences(X_dev_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Get the y labels\n",
    "y_train = train_df['label-coarse']\n",
    "y_dev = dev_df['label-coarse']\n",
    "y_test = test_df['label-coarse']\n",
    "\n",
    "# Convert the labels to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_dev = to_categorical(y_dev)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3,    4, 1435, 1091,   10,  461, 3214,    1,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0], dtype=int32),\n",
       " array([0., 0., 1., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = len(word2vec['apple']) # Any word vector dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the unqiue_tokens with the tokens as keys and interger values as values\n",
    "word_index = {}\n",
    "for i, token in enumerate(unique_tokens):\n",
    "    word_index[token] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros(shape=(vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word2vec[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 37, 300)           2451300   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 37, 512)           1665024   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 37, 512)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               328192    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4445161 (16.96 MB)\n",
      "Trainable params: 1993861 (7.61 MB)\n",
      "Non-trainable params: 2451300 (9.35 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix), trainable=False),\n",
    "    LSTM(512, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "78/78 [==============================] - 19s 226ms/step - loss: 1.6154 - accuracy: 0.2205 - val_loss: 1.6092 - val_accuracy: 0.1940\n",
      "Epoch 2/20\n",
      "78/78 [==============================] - 17s 223ms/step - loss: 1.5081 - accuracy: 0.3037 - val_loss: 1.4901 - val_accuracy: 0.3040\n",
      "Epoch 3/20\n",
      "78/78 [==============================] - 19s 237ms/step - loss: 1.4228 - accuracy: 0.3532 - val_loss: 1.4532 - val_accuracy: 0.3400\n",
      "Epoch 4/20\n",
      "78/78 [==============================] - 18s 229ms/step - loss: 1.3087 - accuracy: 0.4196 - val_loss: 1.2068 - val_accuracy: 0.4560\n",
      "Epoch 5/20\n",
      "78/78 [==============================] - 18s 237ms/step - loss: 1.1545 - accuracy: 0.4968 - val_loss: 1.1029 - val_accuracy: 0.5360\n",
      "Epoch 6/20\n",
      "78/78 [==============================] - 18s 232ms/step - loss: 1.0724 - accuracy: 0.5436 - val_loss: 1.1028 - val_accuracy: 0.5380\n",
      "Epoch 7/20\n",
      "78/78 [==============================] - 17s 222ms/step - loss: 1.0539 - accuracy: 0.5628 - val_loss: 1.0820 - val_accuracy: 0.5800\n",
      "Epoch 8/20\n",
      "78/78 [==============================] - 17s 224ms/step - loss: 0.9575 - accuracy: 0.6171 - val_loss: 0.9087 - val_accuracy: 0.6240\n",
      "Epoch 9/20\n",
      "78/78 [==============================] - 18s 234ms/step - loss: 0.9520 - accuracy: 0.6145 - val_loss: 0.9926 - val_accuracy: 0.6240\n",
      "Epoch 10/20\n",
      "78/78 [==============================] - 18s 234ms/step - loss: 0.8270 - accuracy: 0.6721 - val_loss: 0.7829 - val_accuracy: 0.7220\n",
      "Epoch 11/20\n",
      "78/78 [==============================] - 17s 218ms/step - loss: 0.7848 - accuracy: 0.7171 - val_loss: 0.7956 - val_accuracy: 0.7140\n",
      "Epoch 12/20\n",
      "78/78 [==============================] - 17s 223ms/step - loss: 0.6823 - accuracy: 0.7464 - val_loss: 0.7628 - val_accuracy: 0.7200\n",
      "Epoch 13/20\n",
      "78/78 [==============================] - 18s 227ms/step - loss: 0.6294 - accuracy: 0.7664 - val_loss: 0.7158 - val_accuracy: 0.7340\n",
      "Epoch 14/20\n",
      "78/78 [==============================] - 18s 226ms/step - loss: 0.5984 - accuracy: 0.7845 - val_loss: 0.7211 - val_accuracy: 0.7400\n",
      "Epoch 15/20\n",
      "78/78 [==============================] - 18s 230ms/step - loss: 0.5588 - accuracy: 0.8019 - val_loss: 0.7022 - val_accuracy: 0.7380\n",
      "Epoch 16/20\n",
      "78/78 [==============================] - 18s 234ms/step - loss: 0.5236 - accuracy: 0.8166 - val_loss: 0.6987 - val_accuracy: 0.7560\n",
      "Epoch 17/20\n",
      "78/78 [==============================] - 18s 226ms/step - loss: 0.4878 - accuracy: 0.8308 - val_loss: 0.6830 - val_accuracy: 0.7640\n",
      "Epoch 18/20\n",
      "78/78 [==============================] - 18s 228ms/step - loss: 0.4712 - accuracy: 0.8378 - val_loss: 0.6552 - val_accuracy: 0.7760\n",
      "Epoch 19/20\n",
      "78/78 [==============================] - 18s 225ms/step - loss: 0.4308 - accuracy: 0.8546 - val_loss: 0.6358 - val_accuracy: 0.7820\n",
      "Epoch 20/20\n",
      "78/78 [==============================] - 18s 230ms/step - loss: 0.4070 - accuracy: 0.8677 - val_loss: 0.6630 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x157f510c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_dev_padded, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 47ms/step - loss: 0.5807 - accuracy: 0.8060\n",
      "Test accuracy: 0.8059999942779541\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test samples\n",
    "predictions = model.predict(X_test_padded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0612907e-03, 5.8901549e-04, 1.4004789e-04, 4.7731010e-04,\n",
       "        9.9773228e-01],\n",
       "       [5.5304214e-02, 7.6328820e-01, 8.1286289e-02, 6.9917008e-02,\n",
       "        3.0204363e-02],\n",
       "       [1.0437068e-03, 1.4343505e-02, 2.0909689e-03, 9.8083234e-01,\n",
       "        1.6894542e-03],\n",
       "       [9.7675872e-01, 5.9067165e-03, 1.5905067e-02, 7.3162297e-04,\n",
       "        6.9796975e-04],\n",
       "       [1.1127209e-03, 7.0711452e-04, 1.5907611e-04, 5.7052320e-04,\n",
       "        9.9745053e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
