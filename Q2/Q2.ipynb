{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels being merged to new category:  [2, 5]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.drop(columns=['label-fine'])\n",
    "test_df = test_df.drop(columns=['label-fine'])\n",
    "\n",
    "# Creating developmental set of 500 rows from train set\n",
    "train_df, dev_df = train_test_split(train_df, test_size=(500/len(train_df)), random_state=42)\n",
    "\n",
    "counts = train_df['label-coarse'].value_counts()\n",
    "\n",
    "# Find the labels with the lowest frequencies\n",
    "lowest_frequency = [counts.index[-1], counts.index[-2]]\n",
    "print(\"Labels being merged to new category: \", lowest_frequency)\n",
    "\n",
    "# Replace these labels with new label: 6\n",
    "train_df.loc[(train_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = 6\n",
    "dev_df.loc[(dev_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = 6\n",
    "test_df.loc[(test_df['label-coarse'].isin(lowest_frequency)), 'label-coarse'] = 6\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_df = pd.get_dummies(train_df, columns=['label-coarse']).replace(True, 1).replace(False, 0)\n",
    "dev_df = pd.get_dummies(dev_df, columns=['label-coarse']).replace(True, 1).replace(False, 0)\n",
    "test_df = pd.get_dummies(test_df, columns=['label-coarse']).replace(True, 1).replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label-coarse_0</th>\n",
       "      <th>label-coarse_1</th>\n",
       "      <th>label-coarse_3</th>\n",
       "      <th>label-coarse_4</th>\n",
       "      <th>label-coarse_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>What is Mikhail Gorbachev 's middle initial ?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>How does the tail affect the flight of a kite ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>What were the first three cities to have a pop...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>What is the movie Jonathan Livingstone Seagull ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>What is a fear of home surroundings ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>How much Coca Cola is drunk in one day in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>What cathedral was Thomas Becket murdered in ?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>What character in The Beverly Hillbillies has ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>What does the River Seine empty into ?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>What U.S. Congressman said : `` Keep the faith...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4952 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label-coarse_0  \\\n",
       "4943      What is Mikhail Gorbachev 's middle initial ?               0   \n",
       "2346    How does the tail affect the flight of a kite ?               1   \n",
       "1835  What were the first three cities to have a pop...               0   \n",
       "4047   What is the movie Jonathan Livingstone Seagull ?               0   \n",
       "5097              What is a fear of home surroundings ?               0   \n",
       "...                                                 ...             ...   \n",
       "3772  How much Coca Cola is drunk in one day in the ...               0   \n",
       "5191     What cathedral was Thomas Becket murdered in ?               0   \n",
       "5226  What character in The Beverly Hillbillies has ...               0   \n",
       "5390             What does the River Seine empty into ?               0   \n",
       "860   What U.S. Congressman said : `` Keep the faith...               0   \n",
       "\n",
       "      label-coarse_1  label-coarse_3  label-coarse_4  label-coarse_6  \n",
       "4943               0               0               0               1  \n",
       "2346               0               0               0               0  \n",
       "1835               0               0               0               1  \n",
       "4047               1               0               0               0  \n",
       "5097               1               0               0               0  \n",
       "...              ...             ...             ...             ...  \n",
       "3772               0               0               1               0  \n",
       "5191               0               0               0               1  \n",
       "5226               0               1               0               0  \n",
       "5390               0               0               0               1  \n",
       "860                0               1               0               0  \n",
       "\n",
       "[4952 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about ~30 mins for first run, ~30 seconds afterwards\n",
    "word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences in all dataframes using nltk word_tokenize\n",
    "train_df['tokenized'] = train_df['text'].apply(word_tokenize)\n",
    "dev_df['tokenized'] = dev_df['text'].apply(word_tokenize)\n",
    "test_df['tokenized'] = test_df['text'].apply(word_tokenize)\n",
    "\n",
    "# Declaring '<pad>' as the padding token\n",
    "word2vec['<pad>'] = np.zeros(300)\n",
    "\n",
    "# Pad the tokenized sentences to make them all the same length = max length of all sentences\n",
    "max_len = max(train_df['tokenized'].apply(len).max(), dev_df['tokenized'].apply(len).max(), test_df['tokenized'].apply(len).max())\n",
    "train_df['tokenized'] = train_df['tokenized'].apply(lambda x: x + ['<pad>'] * (max_len - len(x)))\n",
    "dev_df['tokenized'] = dev_df['tokenized'].apply(lambda x: x + ['<pad>'] * (max_len - len(x)))\n",
    "test_df['tokenized'] = test_df['tokenized'].apply(lambda x: x + ['<pad>'] * (max_len - len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_vectors(sentence):\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        # if word is in word2vec, append the word vector to the sentence vector\n",
    "        if word in word2vec:\n",
    "            sentence_vector.append(word2vec[word])\n",
    "        else:\n",
    "            sentence_vector.append(word2vec['<pad>'])\n",
    "    return sentence_vector\n",
    "\n",
    "# Create sentence vectors for all sentences in all dataframes\n",
    "train_df['sentence_vectors'] = train_df['tokenized'].apply(create_sentence_vectors)\n",
    "dev_df['sentence_vectors'] = dev_df['tokenized'].apply(create_sentence_vectors)\n",
    "test_df['sentence_vectors'] = test_df['tokenized'].apply(create_sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array([np.array(sentence) for sentence in train_df['sentence_vectors']])\n",
    "train_y = np.array([np.array(row[1].tolist()) for row in train_df[['label-coarse_0', 'label-coarse_1', 'label-coarse_3', 'label-coarse_4','label-coarse_6']].iterrows()])\n",
    "\n",
    "dev_X = np.array([np.array(sentence) for sentence in dev_df['sentence_vectors']])\n",
    "dev_y = np.array([np.array(row[1].tolist()) for row in dev_df[['label-coarse_0', 'label-coarse_1', 'label-coarse_3', 'label-coarse_4','label-coarse_6']].iterrows()])\n",
    "\n",
    "test_X = np.array([np.array(sentence) for sentence in test_df['sentence_vectors']])\n",
    "test_y = np.array([np.array(row[1].tolist()) for row in test_df[['label-coarse_0', 'label-coarse_1', 'label-coarse_3', 'label-coarse_4','label-coarse_6']].iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4952, 37, 300),\n",
       " (4952, 5),\n",
       " (500, 37, 300),\n",
       " (500, 5),\n",
       " (500, 37, 300),\n",
       " (500, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, dev_X.shape, dev_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 37, 256)           570368    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 768133 (2.93 MB)\n",
      "Trainable params: 768133 (2.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape= (37, 300) ,return_sequences=True),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 21ms/step - loss: 0.9345 - accuracy: 0.6360\n",
      "Dev loss: 0.9344730377197266, Dev accuracy: 0.6359999775886536\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8439 - accuracy: 0.6620\n",
      "Dev loss: 0.8438646197319031, Dev accuracy: 0.6620000004768372\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7123 - accuracy: 0.7480\n",
      "Dev loss: 0.7122973203659058, Dev accuracy: 0.7480000257492065\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7721 - accuracy: 0.7620\n",
      "Dev loss: 0.7720882892608643, Dev accuracy: 0.7620000243186951\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6452 - accuracy: 0.7680\n",
      "Dev loss: 0.6451711058616638, Dev accuracy: 0.7680000066757202\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6588 - accuracy: 0.8120\n",
      "Dev loss: 0.6587889194488525, Dev accuracy: 0.8119999766349792\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5814 - accuracy: 0.8300\n",
      "Dev loss: 0.5814089179039001, Dev accuracy: 0.8299999833106995\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5878 - accuracy: 0.8300\n",
      "Dev loss: 0.5878423452377319, Dev accuracy: 0.8299999833106995\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5998 - accuracy: 0.7960\n",
      "Dev loss: 0.5998224020004272, Dev accuracy: 0.7960000038146973\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6924 - accuracy: 0.7840\n",
      "Dev loss: 0.6923705339431763, Dev accuracy: 0.7839999794960022\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5093 - accuracy: 0.8520\n",
      "Dev loss: 0.5092801451683044, Dev accuracy: 0.8519999980926514\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4880 - accuracy: 0.8620\n",
      "Dev loss: 0.48796334862709045, Dev accuracy: 0.8619999885559082\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5101 - accuracy: 0.8520\n",
      "Dev loss: 0.5100526213645935, Dev accuracy: 0.8519999980926514\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5192 - accuracy: 0.8460\n",
      "Dev loss: 0.5191735029220581, Dev accuracy: 0.8460000157356262\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5646 - accuracy: 0.8380\n",
      "Dev loss: 0.5646214485168457, Dev accuracy: 0.8379999995231628\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4539 - accuracy: 0.8760\n",
      "Dev loss: 0.4539499878883362, Dev accuracy: 0.8759999871253967\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4670 - accuracy: 0.8680\n",
      "Dev loss: 0.46704208850860596, Dev accuracy: 0.8679999709129333\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5357 - accuracy: 0.8500\n",
      "Dev loss: 0.5356558561325073, Dev accuracy: 0.8500000238418579\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4882 - accuracy: 0.8640\n",
      "Dev loss: 0.48815590143203735, Dev accuracy: 0.8640000224113464\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5567 - accuracy: 0.8580\n",
      "Dev loss: 0.5567355751991272, Dev accuracy: 0.8579999804496765\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    for i in range(0, len(train_X), batch_size):\n",
    "        # Select a batch of data\n",
    "        X_batch = train_X[i:i + batch_size]\n",
    "        y_batch = train_y[i:i + batch_size]\n",
    "\n",
    "        # Train the model on the current batch\n",
    "        model.train_on_batch(X_batch, y_batch)\n",
    "    \n",
    "    # Evaluate the model or perform other tasks at the end of each epoch\n",
    "    loss, accuracy = model.evaluate(dev_X, dev_y)\n",
    "    print(f'Dev loss: {loss}, Dev accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5391 - accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using Accuracy\n",
    "loss, accuracy = model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5390982031822205, 0.878000020980835)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
